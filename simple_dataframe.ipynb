{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063080ca-d4be-4ba4-b069-84dc1be7fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from lib.configuration import configure_spark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146096ef-bef0-491b-9c1a-3d46b3a58d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bdb52f-16c6-4c5a-8883-dac21d329cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Hello Spark!\")\n",
    "\n",
    "spark = configure_spark_session(spark, Path().resolve()) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb4e81-bfd3-44a7-ace6-a46f8c985bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .csv(\"data/sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01541fa4-1d46-46cc-9765-d4cd459e448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ed88d-b2db-415f-8993-6386107bfe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6667965-b74d-4706-8e5c-b144626db3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.where(\"Age < 40\") \\\n",
    "    .select(\"Age\", \"Gender\", \"Country\", \"state\") \\\n",
    "    .groupBy(\"Country\") \\ # Causes a shuffle/sort\n",
    "    .count()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab88fac-ba15-4b59-bf10-00394dfc0b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/01/18 03:35:21 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 245832 ms exceeds timeout 120000 ms\n",
      "25/01/18 03:35:21 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "25/01/18 03:35:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:35:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:35:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:35:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:35:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:35:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:35:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:35:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:40:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:40:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:40:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:40:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:40:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:40:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:40:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:40:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:41:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:41:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:45:23 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:45:23 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:45:33 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:45:33 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:45:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:45:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:45:53 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:45:53 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:46:03 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:46:03 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:50:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:50:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:50:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:50:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:50:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:50:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:50:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:50:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:51:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 17 more\n",
      "25/01/18 03:51:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:51:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:51:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:51:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:51:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:51:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:51:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:51:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:51:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:51:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:51:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:52:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:52:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 17 more\n",
      "25/01/18 03:52:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:52:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:52:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:52:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:52:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:52:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:52:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:52:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:52:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:52:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:53:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:53:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:53:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:53:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:53:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:53:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:53:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:53:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:53:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:53:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:53:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:53:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:54:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:54:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:54:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:54:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:54:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 17 more\n",
      "25/01/18 03:54:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:54:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:54:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:54:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:54:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:54:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:54:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:55:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 17 more\n",
      "25/01/18 03:55:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:55:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 17 more\n",
      "25/01/18 03:55:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:55:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:55:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:55:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:55:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:55:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 17 more\n",
      "25/01/18 03:55:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:55:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:55:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:56:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 17 more\n",
      "25/01/18 03:56:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:56:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:56:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:56:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:56:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:56:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:56:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 17 more\n",
      "25/01/18 03:56:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:56:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:56:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 17 more\n",
      "25/01/18 03:56:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:57:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:57:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:57:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:57:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:57:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:57:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 8 more\n",
      "25/01/18 03:57:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 17 more\n",
      "25/01/18 03:57:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:57:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 17 more\n",
      "25/01/18 03:57:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:57:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 17 more\n",
      "25/01/18 03:57:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.72:61416\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\t... 3 more\n",
      "25/01/18 03:57:56 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "print(df.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4683717-d220-4059-bb09-4c6a172a4f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
